{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1971a3a-2d3a-4097-8f72-6a9e20d7e94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austin/code/composer/composer/trainer/trainer.py:776: UserWarning: No optimizer was specified. Defaulting to DecoupledSGDW(lr=0.1)\n",
      "  warnings.warn(('No optimizer was specified. Defaulting to '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import composer.models\n",
    "from composer import Trainer\n",
    "# Example algorithms to train with\n",
    "from composer.algorithms import CutOut, LabelSmoothing\n",
    "\n",
    "\n",
    "# Your custom model\n",
    "class SimpleModel(composer.models.ComposerClassifier):\n",
    "    \"\"\"Your custom model.\"\"\"\n",
    "\n",
    "    def __init__(self, num_hidden: int, num_classes: int):\n",
    "        module = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(start_dim=1),\n",
    "            torch.nn.Linear(28 * 28, num_hidden),\n",
    "            torch.nn.Linear(num_hidden, num_classes),\n",
    "        )\n",
    "        self.num_classes = num_classes\n",
    "        super().__init__(module=module)\n",
    "\n",
    "\n",
    "# Your custom train dataloader\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=datasets.MNIST('.datasets/', train=True, transform=transforms.ToTensor(), download=True),\n",
    "    drop_last=False,\n",
    "    shuffle=True,\n",
    "    batch_size=256,\n",
    ")\n",
    "\n",
    "# Your custom eval dataloader\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=datasets.MNIST('.datasets/', train=False, transform=transforms.ToTensor()),\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    batch_size=256,\n",
    ")\n",
    "\n",
    "# Initialize Trainer with custom model, custom train and eval datasets, and algorithms to train with\n",
    "trainer = Trainer(model=SimpleModel(num_hidden=128, num_classes=10),\n",
    "                  train_dataloader=train_dataloader,\n",
    "                  eval_dataloader=eval_dataloader,\n",
    "                  max_duration='3ep',\n",
    "                  algorithms=[CutOut(num_holes=1, length=0.5), LabelSmoothing(0.1)])\n",
    "\n",
    "# trainer.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214d76cc-8ef4-4596-b456-894c5aa9b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def adjust_momentum(optimizer, momentum):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['momentum'] = momentum\n",
    "        \n",
    "        \n",
    "def get_lr(optimizer):\n",
    "    return optimizer.param_groups[0]['lr']\n",
    "\n",
    "\n",
    "def get_momentum(optimizer):\n",
    "    return optimizer.param_groups[0].get('momentum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c54eb5-f328-4e36-a073-370722e29be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from composer import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "850f7700-82e9-47cd-8aba-8e2f0710f5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = trainer.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8410d5-3750-4bd2-b253-410f87fef6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp(epoch=0, batch=0, sample=0, token=0, batch_in_epoch=0, sample_in_epoch=0, token_in_epoch=0, total_wct=datetime.timedelta(0), epoch_wct=datetime.timedelta(0), batch_wct=datetime.timedelta(0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fdc4219-ced9-45c9-b052-9a9239663fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScheduleAnything(Callback):\n",
    "    \n",
    "    def __init__(self, state, function):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2d68db8-115d-488e-a375-6ac130b90ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from composer.optim import LinearWithWarmupScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de823fef-a197-4762-b44e-c2b364551cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = LinearWithWarmupScheduler(t_warmup=\"10ba\", t_max='100ba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b354d67b-2760-4450-ae88-a629119e34f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr(scheduler, state, num_batches=100):\n",
    "    lrs = []\n",
    "    for batch in range(num_batches):\n",
    "        lrs.append(scheduler(state))\n",
    "        state.timestamp = state.timestamp.to_next_batch()\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2876fa01-d162-4d62-b6b8-fdaa3be308e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = plot_lr(scheduler, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a871ecb7-07e3-462b-85ab-9cfddf134b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2243c41a-f416-40de-8d85-e8b3b0f650df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcc93e0ceb0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "274bdac2-747b-47a2-a2a7-be2a65ab05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.datasets import CocoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b942d-26d6-491a-81a0-34f6d6248c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CocoDataset(ann_file='../mmdetection/data/coco/train2017.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ef85c-4b48-4b65-95e6-be68b25eeb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ec4705d8-8f06-4331-b3d8-c0a2110e1a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "698b9f6e-119e-4f95-b6e4-040b9aa3313f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/79/3kl5b0ss1035q1pd2bj6rsjh0000gn/T/ipykernel_54389/2161145907.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "build_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c3e46bcc-56a8-435d-a507-ae7b384f8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c3d4bb58-e6d3-49ba-9e62-79849232036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.utils import replace_cfg_vals, update_data_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "11ac6823-52c1-44c4-9ce8-78dccb7aab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config.fromfile('../mmdetection/configs/yolox/yolox_s_8x8_300e_coco.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e6444229-85f2-4f5b-97c6-8a419d797a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: ../mmdetection/configs/yolox/yolox_s_8x8_300e_coco.py): {'optimizer': {'type': 'SGD', 'lr': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': True, 'paramwise_cfg': {'norm_decay_mult': 0.0, 'bias_decay_mult': 0.0}}, 'optimizer_config': {'grad_clip': None}, 'lr_config': {'policy': 'YOLOX', 'warmup': 'exp', 'by_epoch': False, 'warmup_by_epoch': True, 'warmup_ratio': 1, 'warmup_iters': 5, 'num_last_epochs': 15, 'min_lr_ratio': 0.05}, 'runner': {'type': 'EpochBasedRunner', 'max_epochs': 300}, 'checkpoint_config': {'interval': 10}, 'log_config': {'interval': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'custom_hooks': [{'type': 'YOLOXModeSwitchHook', 'num_last_epochs': 15, 'priority': 48}, {'type': 'SyncNormHook', 'num_last_epochs': 15, 'interval': 10, 'priority': 48}, {'type': 'ExpMomentumEMAHook', 'resume_from': None, 'momentum': 0.0001, 'priority': 49}], 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'opencv_num_threads': 0, 'mp_start_method': 'fork', 'auto_scale_lr': {'enable': False, 'base_batch_size': 64}, 'img_scale': (640, 640), 'model': {'type': 'YOLOX', 'input_size': (640, 640), 'random_size_range': (15, 25), 'random_size_interval': 10, 'backbone': {'type': 'CSPDarknet', 'deepen_factor': 0.33, 'widen_factor': 0.5}, 'neck': {'type': 'YOLOXPAFPN', 'in_channels': [128, 256, 512], 'out_channels': 128, 'num_csp_blocks': 1}, 'bbox_head': {'type': 'YOLOXHead', 'num_classes': 80, 'in_channels': 128, 'feat_channels': 128}, 'train_cfg': {'assigner': {'type': 'SimOTAAssigner', 'center_radius': 2.5}}, 'test_cfg': {'score_thr': 0.01, 'nms': {'type': 'nms', 'iou_threshold': 0.65}}}, 'data_root': 'data/coco/', 'dataset_type': 'CocoDataset', 'train_pipeline': [{'type': 'Mosaic', 'img_scale': (640, 640), 'pad_val': 114.0}, {'type': 'RandomAffine', 'scaling_ratio_range': (0.1, 2), 'border': (-320, -320)}, {'type': 'MixUp', 'img_scale': (640, 640), 'ratio_range': (0.8, 1.6), 'pad_val': 114.0}, {'type': 'YOLOXHSVRandomAug'}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Resize', 'img_scale': (640, 640), 'keep_ratio': True}, {'type': 'Pad', 'pad_to_square': True, 'pad_val': {'img': (114.0, 114.0, 114.0)}}, {'type': 'FilterAnnotations', 'min_gt_bbox_wh': (1, 1), 'keep_empty': False}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}], 'train_dataset': {'type': 'MultiImageMixDataset', 'dataset': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_train2017.json', 'img_prefix': 'data/coco/train2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True}], 'filter_empty_gt': False}, 'pipeline': [{'type': 'Mosaic', 'img_scale': (640, 640), 'pad_val': 114.0}, {'type': 'RandomAffine', 'scaling_ratio_range': (0.1, 2), 'border': (-320, -320)}, {'type': 'MixUp', 'img_scale': (640, 640), 'ratio_range': (0.8, 1.6), 'pad_val': 114.0}, {'type': 'YOLOXHSVRandomAug'}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Resize', 'img_scale': (640, 640), 'keep_ratio': True}, {'type': 'Pad', 'pad_to_square': True, 'pad_val': {'img': (114.0, 114.0, 114.0)}}, {'type': 'FilterAnnotations', 'min_gt_bbox_wh': (1, 1), 'keep_empty': False}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}]}, 'test_pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (640, 640), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Pad', 'pad_to_square': True, 'pad_val': {'img': (114.0, 114.0, 114.0)}}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img']}]}], 'data': {'samples_per_gpu': 8, 'workers_per_gpu': 4, 'persistent_workers': True, 'train': {'type': 'MultiImageMixDataset', 'dataset': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_train2017.json', 'img_prefix': 'data/coco/train2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True}], 'filter_empty_gt': False}, 'pipeline': [{'type': 'Mosaic', 'img_scale': (640, 640), 'pad_val': 114.0}, {'type': 'RandomAffine', 'scaling_ratio_range': (0.1, 2), 'border': (-320, -320)}, {'type': 'MixUp', 'img_scale': (640, 640), 'ratio_range': (0.8, 1.6), 'pad_val': 114.0}, {'type': 'YOLOXHSVRandomAug'}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Resize', 'img_scale': (640, 640), 'keep_ratio': True}, {'type': 'Pad', 'pad_to_square': True, 'pad_val': {'img': (114.0, 114.0, 114.0)}}, {'type': 'FilterAnnotations', 'min_gt_bbox_wh': (1, 1), 'keep_empty': False}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}]}, 'val': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_val2017.json', 'img_prefix': 'data/coco/val2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (640, 640), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Pad', 'pad_to_square': True, 'pad_val': {'img': (114.0, 114.0, 114.0)}}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img']}]}]}, 'test': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_val2017.json', 'img_prefix': 'data/coco/val2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (640, 640), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Pad', 'pad_to_square': True, 'pad_val': {'img': (114.0, 114.0, 114.0)}}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img']}]}]}}, 'max_epochs': 300, 'num_last_epochs': 15, 'interval': 10, 'evaluation': {'save_best': 'auto', 'interval': 10, 'dynamic_intervals': [(285, 1)], 'metric': 'bbox'}}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e6dcf599-79c6-4b7e-9318-8b109bb94e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.get('test_cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a52db32f-08c4-4fcb-b054-2fbaf2db47cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'YOLOX',\n",
       " 'input_size': (640, 640),\n",
       " 'random_size_range': (15, 25),\n",
       " 'random_size_interval': 10,\n",
       " 'backbone': {'type': 'CSPDarknet',\n",
       "  'deepen_factor': 0.33,\n",
       "  'widen_factor': 0.5},\n",
       " 'neck': {'type': 'YOLOXPAFPN',\n",
       "  'in_channels': [128, 256, 512],\n",
       "  'out_channels': 128,\n",
       "  'num_csp_blocks': 1},\n",
       " 'bbox_head': {'type': 'YOLOXHead',\n",
       "  'num_classes': 80,\n",
       "  'in_channels': 128,\n",
       "  'feat_channels': 128},\n",
       " 'train_cfg': {'assigner': {'type': 'SimOTAAssigner', 'center_radius': 2.5}},\n",
       " 'test_cfg': {'score_thr': 0.01,\n",
       "  'nms': {'type': 'nms', 'iou_threshold': 0.65}}}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d3318633-0cc4-4142-be54-1e196cfc5cf8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 00:53:42,389 - mmcv - INFO - initialize CSPDarknet with init_cfg {'type': 'Kaiming', 'layer': 'Conv2d', 'a': 2.23606797749979, 'distribution': 'uniform', 'mode': 'fan_in', 'nonlinearity': 'leaky_relu'}\n",
      "2022-07-06 00:53:42,411 - mmcv - INFO - initialize YOLOXPAFPN with init_cfg {'type': 'Kaiming', 'layer': 'Conv2d', 'a': 2.23606797749979, 'distribution': 'uniform', 'mode': 'fan_in', 'nonlinearity': 'leaky_relu'}\n",
      "2022-07-06 00:53:42,427 - mmcv - INFO - initialize YOLOXHead with init_cfg {'type': 'Kaiming', 'layer': 'Conv2d', 'a': 2.23606797749979, 'distribution': 'uniform', 'mode': 'fan_in', 'nonlinearity': 'leaky_relu'}\n",
      "2022-07-06 00:53:42,438 - mmcv - INFO - \n",
      "backbone.stem.conv.conv.weight - torch.Size([32, 12, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,438 - mmcv - INFO - \n",
      "backbone.stem.conv.bn.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,438 - mmcv - INFO - \n",
      "backbone.stem.conv.bn.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,439 - mmcv - INFO - \n",
      "backbone.stage1.0.conv.weight - torch.Size([64, 32, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,439 - mmcv - INFO - \n",
      "backbone.stage1.0.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,439 - mmcv - INFO - \n",
      "backbone.stage1.0.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,440 - mmcv - INFO - \n",
      "backbone.stage1.1.main_conv.conv.weight - torch.Size([32, 64, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,440 - mmcv - INFO - \n",
      "backbone.stage1.1.main_conv.bn.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,440 - mmcv - INFO - \n",
      "backbone.stage1.1.main_conv.bn.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,440 - mmcv - INFO - \n",
      "backbone.stage1.1.short_conv.conv.weight - torch.Size([32, 64, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,441 - mmcv - INFO - \n",
      "backbone.stage1.1.short_conv.bn.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,441 - mmcv - INFO - \n",
      "backbone.stage1.1.short_conv.bn.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,441 - mmcv - INFO - \n",
      "backbone.stage1.1.final_conv.conv.weight - torch.Size([64, 64, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,442 - mmcv - INFO - \n",
      "backbone.stage1.1.final_conv.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,442 - mmcv - INFO - \n",
      "backbone.stage1.1.final_conv.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,442 - mmcv - INFO - \n",
      "backbone.stage1.1.blocks.0.conv1.conv.weight - torch.Size([32, 32, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,442 - mmcv - INFO - \n",
      "backbone.stage1.1.blocks.0.conv1.bn.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,442 - mmcv - INFO - \n",
      "backbone.stage1.1.blocks.0.conv1.bn.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,443 - mmcv - INFO - \n",
      "backbone.stage1.1.blocks.0.conv2.conv.weight - torch.Size([32, 32, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,443 - mmcv - INFO - \n",
      "backbone.stage1.1.blocks.0.conv2.bn.weight - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,443 - mmcv - INFO - \n",
      "backbone.stage1.1.blocks.0.conv2.bn.bias - torch.Size([32]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,443 - mmcv - INFO - \n",
      "backbone.stage2.0.conv.weight - torch.Size([128, 64, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,443 - mmcv - INFO - \n",
      "backbone.stage2.0.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,444 - mmcv - INFO - \n",
      "backbone.stage2.0.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,444 - mmcv - INFO - \n",
      "backbone.stage2.1.main_conv.conv.weight - torch.Size([64, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,445 - mmcv - INFO - \n",
      "backbone.stage2.1.main_conv.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,445 - mmcv - INFO - \n",
      "backbone.stage2.1.main_conv.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,446 - mmcv - INFO - \n",
      "backbone.stage2.1.short_conv.conv.weight - torch.Size([64, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,446 - mmcv - INFO - \n",
      "backbone.stage2.1.short_conv.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,446 - mmcv - INFO - \n",
      "backbone.stage2.1.short_conv.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,447 - mmcv - INFO - \n",
      "backbone.stage2.1.final_conv.conv.weight - torch.Size([128, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,447 - mmcv - INFO - \n",
      "backbone.stage2.1.final_conv.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,447 - mmcv - INFO - \n",
      "backbone.stage2.1.final_conv.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,448 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.0.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,448 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.0.conv1.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,448 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.0.conv1.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,448 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.0.conv2.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,449 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.0.conv2.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,449 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.0.conv2.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,449 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.1.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,449 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.1.conv1.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,450 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.1.conv1.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,450 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.1.conv2.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,450 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.1.conv2.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,450 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.1.conv2.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,451 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.2.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,451 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.2.conv1.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,451 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.2.conv1.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,451 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.2.conv2.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,452 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.2.conv2.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,452 - mmcv - INFO - \n",
      "backbone.stage2.1.blocks.2.conv2.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,452 - mmcv - INFO - \n",
      "backbone.stage3.0.conv.weight - torch.Size([256, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,452 - mmcv - INFO - \n",
      "backbone.stage3.0.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,453 - mmcv - INFO - \n",
      "backbone.stage3.0.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,453 - mmcv - INFO - \n",
      "backbone.stage3.1.main_conv.conv.weight - torch.Size([128, 256, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,453 - mmcv - INFO - \n",
      "backbone.stage3.1.main_conv.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,454 - mmcv - INFO - \n",
      "backbone.stage3.1.main_conv.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,454 - mmcv - INFO - \n",
      "backbone.stage3.1.short_conv.conv.weight - torch.Size([128, 256, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,454 - mmcv - INFO - \n",
      "backbone.stage3.1.short_conv.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,454 - mmcv - INFO - \n",
      "backbone.stage3.1.short_conv.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,455 - mmcv - INFO - \n",
      "backbone.stage3.1.final_conv.conv.weight - torch.Size([256, 256, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,455 - mmcv - INFO - \n",
      "backbone.stage3.1.final_conv.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,455 - mmcv - INFO - \n",
      "backbone.stage3.1.final_conv.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,455 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.0.conv1.conv.weight - torch.Size([128, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,456 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.0.conv1.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,456 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.0.conv1.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,456 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.0.conv2.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,456 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.0.conv2.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,457 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.0.conv2.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,457 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.1.conv1.conv.weight - torch.Size([128, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,457 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.1.conv1.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,457 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.1.conv1.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,457 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.1.conv2.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,458 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.1.conv2.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,458 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.1.conv2.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,458 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.2.conv1.conv.weight - torch.Size([128, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,458 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.2.conv1.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,458 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.2.conv1.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,459 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.2.conv2.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,459 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.2.conv2.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,459 - mmcv - INFO - \n",
      "backbone.stage3.1.blocks.2.conv2.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,459 - mmcv - INFO - \n",
      "backbone.stage4.0.conv.weight - torch.Size([512, 256, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,460 - mmcv - INFO - \n",
      "backbone.stage4.0.bn.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,460 - mmcv - INFO - \n",
      "backbone.stage4.0.bn.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,460 - mmcv - INFO - \n",
      "backbone.stage4.1.conv1.conv.weight - torch.Size([256, 512, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,460 - mmcv - INFO - \n",
      "backbone.stage4.1.conv1.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,461 - mmcv - INFO - \n",
      "backbone.stage4.1.conv1.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,461 - mmcv - INFO - \n",
      "backbone.stage4.1.conv2.conv.weight - torch.Size([512, 1024, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,461 - mmcv - INFO - \n",
      "backbone.stage4.1.conv2.bn.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,461 - mmcv - INFO - \n",
      "backbone.stage4.1.conv2.bn.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,462 - mmcv - INFO - \n",
      "backbone.stage4.2.main_conv.conv.weight - torch.Size([256, 512, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,462 - mmcv - INFO - \n",
      "backbone.stage4.2.main_conv.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,462 - mmcv - INFO - \n",
      "backbone.stage4.2.main_conv.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,462 - mmcv - INFO - \n",
      "backbone.stage4.2.short_conv.conv.weight - torch.Size([256, 512, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,462 - mmcv - INFO - \n",
      "backbone.stage4.2.short_conv.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,463 - mmcv - INFO - \n",
      "backbone.stage4.2.short_conv.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,463 - mmcv - INFO - \n",
      "backbone.stage4.2.final_conv.conv.weight - torch.Size([512, 512, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,464 - mmcv - INFO - \n",
      "backbone.stage4.2.final_conv.bn.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,464 - mmcv - INFO - \n",
      "backbone.stage4.2.final_conv.bn.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,464 - mmcv - INFO - \n",
      "backbone.stage4.2.blocks.0.conv1.conv.weight - torch.Size([256, 256, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,465 - mmcv - INFO - \n",
      "backbone.stage4.2.blocks.0.conv1.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,465 - mmcv - INFO - \n",
      "backbone.stage4.2.blocks.0.conv1.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,465 - mmcv - INFO - \n",
      "backbone.stage4.2.blocks.0.conv2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,465 - mmcv - INFO - \n",
      "backbone.stage4.2.blocks.0.conv2.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,465 - mmcv - INFO - \n",
      "backbone.stage4.2.blocks.0.conv2.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,466 - mmcv - INFO - \n",
      "neck.reduce_layers.0.conv.weight - torch.Size([256, 512, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,466 - mmcv - INFO - \n",
      "neck.reduce_layers.0.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,466 - mmcv - INFO - \n",
      "neck.reduce_layers.0.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,466 - mmcv - INFO - \n",
      "neck.reduce_layers.1.conv.weight - torch.Size([128, 256, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,467 - mmcv - INFO - \n",
      "neck.reduce_layers.1.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,467 - mmcv - INFO - \n",
      "neck.reduce_layers.1.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,467 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.main_conv.conv.weight - torch.Size([128, 512, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,467 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.main_conv.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,467 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.main_conv.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,468 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.short_conv.conv.weight - torch.Size([128, 512, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,468 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.short_conv.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,468 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.short_conv.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,468 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.final_conv.conv.weight - torch.Size([256, 256, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,469 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.final_conv.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,469 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.final_conv.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,469 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.blocks.0.conv1.conv.weight - torch.Size([128, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,469 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.blocks.0.conv1.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,469 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.blocks.0.conv1.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,470 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.blocks.0.conv2.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,470 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.blocks.0.conv2.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,470 - mmcv - INFO - \n",
      "neck.top_down_blocks.0.blocks.0.conv2.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,470 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.main_conv.conv.weight - torch.Size([64, 256, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,471 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.main_conv.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,471 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.main_conv.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,471 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.short_conv.conv.weight - torch.Size([64, 256, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,472 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.short_conv.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,472 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.short_conv.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,473 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.final_conv.conv.weight - torch.Size([128, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,473 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.final_conv.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,473 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.final_conv.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,474 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.blocks.0.conv1.conv.weight - torch.Size([64, 64, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,474 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.blocks.0.conv1.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,474 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.blocks.0.conv1.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,474 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.blocks.0.conv2.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,475 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.blocks.0.conv2.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,475 - mmcv - INFO - \n",
      "neck.top_down_blocks.1.blocks.0.conv2.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,475 - mmcv - INFO - \n",
      "neck.downsamples.0.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,475 - mmcv - INFO - \n",
      "neck.downsamples.0.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,476 - mmcv - INFO - \n",
      "neck.downsamples.0.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,476 - mmcv - INFO - \n",
      "neck.downsamples.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,476 - mmcv - INFO - \n",
      "neck.downsamples.1.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,477 - mmcv - INFO - \n",
      "neck.downsamples.1.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,477 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.main_conv.conv.weight - torch.Size([128, 256, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,477 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.main_conv.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,477 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.main_conv.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,478 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.short_conv.conv.weight - torch.Size([128, 256, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,478 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.short_conv.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,478 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.short_conv.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,478 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.final_conv.conv.weight - torch.Size([256, 256, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,479 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.final_conv.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,479 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.final_conv.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,479 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.blocks.0.conv1.conv.weight - torch.Size([128, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,480 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,480 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,480 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.blocks.0.conv2.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,480 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.blocks.0.conv2.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,481 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.0.blocks.0.conv2.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,481 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.main_conv.conv.weight - torch.Size([256, 512, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,481 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.main_conv.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,481 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.main_conv.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,482 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.short_conv.conv.weight - torch.Size([256, 512, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,482 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.short_conv.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,482 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.short_conv.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,482 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.final_conv.conv.weight - torch.Size([512, 512, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,483 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.final_conv.bn.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,483 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.final_conv.bn.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,483 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.blocks.0.conv1.conv.weight - torch.Size([256, 256, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,483 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,483 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,484 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.blocks.0.conv2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,484 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.blocks.0.conv2.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,484 - mmcv - INFO - \n",
      "neck.bottom_up_blocks.1.blocks.0.conv2.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,484 - mmcv - INFO - \n",
      "neck.out_convs.0.conv.weight - torch.Size([128, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,484 - mmcv - INFO - \n",
      "neck.out_convs.0.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,485 - mmcv - INFO - \n",
      "neck.out_convs.0.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,485 - mmcv - INFO - \n",
      "neck.out_convs.1.conv.weight - torch.Size([128, 256, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,485 - mmcv - INFO - \n",
      "neck.out_convs.1.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,485 - mmcv - INFO - \n",
      "neck.out_convs.1.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,486 - mmcv - INFO - \n",
      "neck.out_convs.2.conv.weight - torch.Size([128, 512, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,486 - mmcv - INFO - \n",
      "neck.out_convs.2.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,486 - mmcv - INFO - \n",
      "neck.out_convs.2.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,487 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.0.0.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,487 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.0.0.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,487 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.0.0.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,488 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.0.1.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,488 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.0.1.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,488 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.0.1.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,488 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.1.0.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,489 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.1.0.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,489 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.1.0.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,489 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.1.1.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,489 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.1.1.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,489 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.1.1.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,490 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.2.0.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,490 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.2.0.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,490 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.2.0.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,490 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.2.1.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,491 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.2.1.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,491 - mmcv - INFO - \n",
      "bbox_head.multi_level_cls_convs.2.1.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,491 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.0.0.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,492 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.0.0.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,492 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.0.0.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,492 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.0.1.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,492 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.0.1.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,493 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.0.1.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,493 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.1.0.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,493 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.1.0.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,493 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.1.0.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,494 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.1.1.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,494 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.1.1.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,494 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.1.1.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,494 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.2.0.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,495 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.2.0.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,495 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.2.0.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,495 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.2.1.conv.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,495 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.2.1.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,496 - mmcv - INFO - \n",
      "bbox_head.multi_level_reg_convs.2.1.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of YOLOX  \n",
      " \n",
      "2022-07-06 00:53:42,496 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_cls.0.weight - torch.Size([80, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,496 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_cls.0.bias - torch.Size([80]): \n",
      "Initialized by user-defined `init_weights` in YOLOXHead  \n",
      " \n",
      "2022-07-06 00:53:42,496 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_cls.1.weight - torch.Size([80, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,496 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_cls.1.bias - torch.Size([80]): \n",
      "Initialized by user-defined `init_weights` in YOLOXHead  \n",
      " \n",
      "2022-07-06 00:53:42,497 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_cls.2.weight - torch.Size([80, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,497 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_cls.2.bias - torch.Size([80]): \n",
      "Initialized by user-defined `init_weights` in YOLOXHead  \n",
      " \n",
      "2022-07-06 00:53:42,497 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_reg.0.weight - torch.Size([4, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,497 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_reg.0.bias - torch.Size([4]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,498 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_reg.1.weight - torch.Size([4, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,498 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_reg.1.bias - torch.Size([4]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,498 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_reg.2.weight - torch.Size([4, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,498 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_reg.2.bias - torch.Size([4]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,499 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_obj.0.weight - torch.Size([1, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,499 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_obj.0.bias - torch.Size([1]): \n",
      "Initialized by user-defined `init_weights` in YOLOXHead  \n",
      " \n",
      "2022-07-06 00:53:42,499 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_obj.1.weight - torch.Size([1, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,499 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_obj.1.bias - torch.Size([1]): \n",
      "Initialized by user-defined `init_weights` in YOLOXHead  \n",
      " \n",
      "2022-07-06 00:53:42,500 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_obj.2.weight - torch.Size([1, 128, 1, 1]): \n",
      "KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 \n",
      " \n",
      "2022-07-06 00:53:42,500 - mmcv - INFO - \n",
      "bbox_head.multi_level_conv_obj.2.bias - torch.Size([1]): \n",
      "Initialized by user-defined `init_weights` in YOLOXHead  \n",
      " \n"
     ]
    }
   ],
   "source": [
    "model = build_detector(\n",
    "    config.model,\n",
    "    train_cfg=config.get('train_cfg'),\n",
    "    test_cfg=config.get('test_cfg'))\n",
    "model.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "805511f2-99d7-4325-8ffd-d281458a32bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "5e508159-cc3c-47e1-a803-bb8a8bc750da",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mmdet.models.detectors.yolox.YOLOX"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "00586de7-1f2b-4465-b5d0-5fab49c28400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model, mmdet.models.detectors.BaseDetector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8c4de9e0-7462-4ff2-be3a-a26e3a9f5035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'YOLOX',\n",
       " 'input_size': (640, 640),\n",
       " 'random_size_range': (15, 25),\n",
       " 'random_size_interval': 10,\n",
       " 'backbone': {'type': 'CSPDarknet',\n",
       "  'deepen_factor': 0.33,\n",
       "  'widen_factor': 0.5},\n",
       " 'neck': {'type': 'YOLOXPAFPN',\n",
       "  'in_channels': [128, 256, 512],\n",
       "  'out_channels': 128,\n",
       "  'num_csp_blocks': 1},\n",
       " 'bbox_head': {'type': 'YOLOXHead',\n",
       "  'num_classes': 80,\n",
       "  'in_channels': 128,\n",
       "  'feat_channels': 128,\n",
       "  'train_cfg': {'assigner': {'type': 'SimOTAAssigner', 'center_radius': 2.5}},\n",
       "  'test_cfg': {'score_thr': 0.01,\n",
       "   'nms': {'type': 'nms', 'iou_threshold': 0.65}}},\n",
       " 'train_cfg': {'assigner': {'type': 'SimOTAAssigner', 'center_radius': 2.5}},\n",
       " 'test_cfg': {'score_thr': 0.01,\n",
       "  'nms': {'type': 'nms', 'iou_threshold': 0.65}}}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b5864ad5-8673-40b5-b118-35a70eb900e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations_trainval2017.zip tmpwe0qqkmy\n",
      "test2017.zip                 train2017.zip\n",
      "tmp79d99qgo                  val2017.zip\n",
      "tmps_vm3dc2\n"
     ]
    }
   ],
   "source": [
    "!ls ../mmdetection/data/coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b52ce9a6-3a10-4fae-a2b0-01c342fc81d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'MultiImageMixDataset',\n",
       " 'dataset': {'type': 'CocoDataset',\n",
       "  'ann_file': '../mmdetection/data/coco/annotations/instances_train2017.json',\n",
       "  'img_prefix': '../mmdetection/data/coco/train2017',\n",
       "  'pipeline': [{'type': 'LoadImageFromFile'},\n",
       "   {'type': 'LoadAnnotations', 'with_bbox': True}],\n",
       "  'filter_empty_gt': False},\n",
       " 'pipeline': [{'type': 'Mosaic', 'img_scale': (640, 640), 'pad_val': 114.0},\n",
       "  {'type': 'RandomAffine',\n",
       "   'scaling_ratio_range': (0.5, 1.5),\n",
       "   'border': (-320, -320)},\n",
       "  {'type': 'YOLOXHSVRandomAug'},\n",
       "  {'type': 'RandomFlip', 'flip_ratio': 0.5},\n",
       "  {'type': 'Resize', 'img_scale': (640, 640), 'keep_ratio': True},\n",
       "  {'type': 'Pad',\n",
       "   'pad_to_square': True,\n",
       "   'pad_val': {'img': (114.0, 114.0, 114.0)}},\n",
       "  {'type': 'FilterAnnotations', 'min_gt_bbox_wh': (1, 1), 'keep_empty': False},\n",
       "  {'type': 'DefaultFormatBundle'},\n",
       "  {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}]}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.data.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "13836feb-cec7-4234-ad68-44bc243a1dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data.train.dataset.ann_file = '../mmdetection/data/coco/annotations/instances_train2017.json'\n",
    "config.data.train.dataset.img_prefix = '../mmdetection/data/coco/train2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c7273259-5724-4933-a192-d3196c07c4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'Mosaic', 'img_scale': (640, 640), 'pad_val': 114.0},\n",
       " {'type': 'RandomAffine',\n",
       "  'scaling_ratio_range': (0.5, 1.5),\n",
       "  'border': (-320, -320)},\n",
       " {'type': 'YOLOXHSVRandomAug'},\n",
       " {'type': 'RandomFlip', 'flip_ratio': 0.5},\n",
       " {'type': 'Resize', 'img_scale': (640, 640), 'keep_ratio': True},\n",
       " {'type': 'Pad',\n",
       "  'pad_to_square': True,\n",
       "  'pad_val': {'img': (114.0, 114.0, 114.0)}},\n",
       " {'type': 'FilterAnnotations', 'min_gt_bbox_wh': (1, 1), 'keep_empty': False},\n",
       " {'type': 'DefaultFormatBundle'},\n",
       " {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.data.train.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8b16d9bf-0409-463b-8d54-042042be68c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=13.97s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset = build_dataset(config.data.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8cca751b-93ae-4019-aba7-6c42d6395bcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'img_metas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/79/3kl5b0ss1035q1pd2bj6rsjh0000gn/T/ipykernel_54389/119041548.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mmcv/runner/fp16_utils.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                 f'method of those classes {supported_types}')\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fp16_enabled'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_enabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mold_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# get the arg spec of the decorated method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'img_metas'"
     ]
    }
   ],
   "source": [
    "model(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "39c38602-7e22-47f7-861c-b762d5ea8e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from mmcv.parallel import collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "703aaa84-b4f9-4014-8022-ca41a8c4ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=4, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "01b36668-4291-4b2b-a505-211758a31871",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5abcdc5d-000a-400f-92f8-6840e203c5c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataContainer' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/79/3kl5b0ss1035q1pd2bj6rsjh0000gn/T/ipykernel_54389/3486555345.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mmcv/runner/fp16_utils.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                 f'method of those classes {supported_types}')\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fp16_enabled'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_enabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mold_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# get the arg spec of the decorated method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mmdet/models/detectors/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img, img_metas, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mmdet/models/detectors/yolox.py\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, img, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_bboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_bboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         losses = super(YOLOX, self).forward_train(img, img_metas, gt_bboxes,\n\u001b[0m\u001b[1;32m     96\u001b[0m                                                   gt_labels, gt_bboxes_ignore)\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mmdet/models/detectors/single_stage.py\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, img, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mof\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSingleStageDetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         losses = self.bbox_head.forward_train(x, img_metas, gt_bboxes,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mmdet/models/detectors/base.py\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, imgs, img_metas, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# in DETR, this is needed for the construction of masks, which is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# then used for the transformer_head.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mbatch_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimg_meta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mimg_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_input_shape'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataContainer' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "66f52684-1ea4-48c5-8cc2-9becc490cc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f95de3825b0>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset[5]['img'].data.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4726b176-1c0e-4ca7-a124-1d51cca15009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Puts each data field into a tensor/DataContainer with outer dimension\u001b[0m\n",
       "\u001b[0;34m    batch size.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Extend default_collate to add support for\u001b[0m\n",
       "\u001b[0;34m    :type:`~mmcv.parallel.DataContainer`. There are 3 cases.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    1. cpu_only = True, e.g., meta data\u001b[0m\n",
       "\u001b[0;34m    2. cpu_only = False, stack = True, e.g., images tensors\u001b[0m\n",
       "\u001b[0;34m    3. cpu_only = False, stack = False, e.g., gt bboxes\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{batch.dtype} is not supported.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataContainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mstacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mstacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mDataContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mstacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_dims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32massert\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_dims\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mmax_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_dims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mmax_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                            \u001b[0;32massert\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_dims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                            \u001b[0mmax_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                     \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mpadded_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_dims\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_dims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                            \u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mpadded_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                            \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mstacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32melif\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_dims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mstacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                            \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                            \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0;34m'pad_dims should be either None or integers (1-3)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mstacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mDataContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.9/site-packages/mmcv/parallel/collate.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "collate??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c7adab42-d850-4e0b-bc9f-1a67fac64ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': {'type': 'SGD',\n",
       "  'lr': 0.01,\n",
       "  'momentum': 0.9,\n",
       "  'weight_decay': 0.0005,\n",
       "  'nesterov': True,\n",
       "  'paramwise_cfg': {'norm_decay_mult': 0.0, 'bias_decay_mult': 0.0}},\n",
       " 'optimizer_config': {'grad_clip': None},\n",
       " 'lr_config': {'policy': 'YOLOX',\n",
       "  'warmup': 'exp',\n",
       "  'by_epoch': False,\n",
       "  'warmup_by_epoch': True,\n",
       "  'warmup_ratio': 1,\n",
       "  'warmup_iters': 5,\n",
       "  'num_last_epochs': 15,\n",
       "  'min_lr_ratio': 0.05},\n",
       " 'runner': {'type': 'EpochBasedRunner', 'max_epochs': 300},\n",
       " 'checkpoint_config': {'interval': 10},\n",
       " 'log_config': {'interval': 50, 'hooks': [{'type': 'TextLoggerHook'}]},\n",
       " 'custom_hooks': [{'type': 'YOLOXModeSwitchHook',\n",
       "   'num_last_epochs': 15,\n",
       "   'priority': 48},\n",
       "  {'type': 'SyncNormHook',\n",
       "   'num_last_epochs': 15,\n",
       "   'interval': 10,\n",
       "   'priority': 48},\n",
       "  {'type': 'ExpMomentumEMAHook',\n",
       "   'resume_from': None,\n",
       "   'momentum': 0.0001,\n",
       "   'priority': 49}],\n",
       " 'dist_params': {'backend': 'nccl'},\n",
       " 'log_level': 'INFO',\n",
       " 'load_from': None,\n",
       " 'resume_from': None,\n",
       " 'workflow': [('train', 1)],\n",
       " 'opencv_num_threads': 0,\n",
       " 'mp_start_method': 'fork',\n",
       " 'auto_scale_lr': {'enable': False, 'base_batch_size': 64},\n",
       " 'img_scale': (640, 640),\n",
       " 'model': {'type': 'YOLOX',\n",
       "  'input_size': (640, 640),\n",
       "  'random_size_range': (10, 20),\n",
       "  'random_size_interval': 10,\n",
       "  'backbone': {'type': 'CSPDarknet',\n",
       "   'deepen_factor': 0.33,\n",
       "   'widen_factor': 0.375},\n",
       "  'neck': {'type': 'YOLOXPAFPN',\n",
       "   'in_channels': [96, 192, 384],\n",
       "   'out_channels': 96,\n",
       "   'num_csp_blocks': 1},\n",
       "  'bbox_head': {'type': 'YOLOXHead',\n",
       "   'num_classes': 80,\n",
       "   'in_channels': 96,\n",
       "   'feat_channels': 96,\n",
       "   'train_cfg': {'assigner': {'type': 'SimOTAAssigner', 'center_radius': 2.5}},\n",
       "   'test_cfg': {'score_thr': 0.01,\n",
       "    'nms': {'type': 'nms', 'iou_threshold': 0.65}}},\n",
       "  'train_cfg': {'assigner': {'type': 'SimOTAAssigner', 'center_radius': 2.5}},\n",
       "  'test_cfg': {'score_thr': 0.01,\n",
       "   'nms': {'type': 'nms', 'iou_threshold': 0.65}}},\n",
       " 'data_root': 'data/coco/',\n",
       " 'dataset_type': 'CocoDataset',\n",
       " 'train_pipeline': [{'type': 'Mosaic',\n",
       "   'img_scale': (640, 640),\n",
       "   'pad_val': 114.0},\n",
       "  {'type': 'RandomAffine',\n",
       "   'scaling_ratio_range': (0.5, 1.5),\n",
       "   'border': (-320, -320)},\n",
       "  {'type': 'YOLOXHSVRandomAug'},\n",
       "  {'type': 'RandomFlip', 'flip_ratio': 0.5},\n",
       "  {'type': 'Resize', 'img_scale': (640, 640), 'keep_ratio': True},\n",
       "  {'type': 'Pad',\n",
       "   'pad_to_square': True,\n",
       "   'pad_val': {'img': (114.0, 114.0, 114.0)}},\n",
       "  {'type': 'FilterAnnotations', 'min_gt_bbox_wh': (1, 1), 'keep_empty': False},\n",
       "  {'type': 'DefaultFormatBundle'},\n",
       "  {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}],\n",
       " 'train_dataset': {'type': 'MultiImageMixDataset',\n",
       "  'dataset': {'type': 'CocoDataset',\n",
       "   'ann_file': 'data/coco/annotations/instances_train2017.json',\n",
       "   'img_prefix': 'data/coco/train2017/',\n",
       "   'pipeline': [{'type': 'LoadImageFromFile'},\n",
       "    {'type': 'LoadAnnotations', 'with_bbox': True}],\n",
       "   'filter_empty_gt': False},\n",
       "  'pipeline': [{'type': 'Mosaic', 'img_scale': (640, 640), 'pad_val': 114.0},\n",
       "   {'type': 'RandomAffine',\n",
       "    'scaling_ratio_range': (0.5, 1.5),\n",
       "    'border': (-320, -320)},\n",
       "   {'type': 'YOLOXHSVRandomAug'},\n",
       "   {'type': 'RandomFlip', 'flip_ratio': 0.5},\n",
       "   {'type': 'Resize', 'img_scale': (640, 640), 'keep_ratio': True},\n",
       "   {'type': 'Pad',\n",
       "    'pad_to_square': True,\n",
       "    'pad_val': {'img': (114.0, 114.0, 114.0)}},\n",
       "   {'type': 'FilterAnnotations',\n",
       "    'min_gt_bbox_wh': (1, 1),\n",
       "    'keep_empty': False},\n",
       "   {'type': 'DefaultFormatBundle'},\n",
       "   {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}]},\n",
       " 'test_pipeline': [{'type': 'LoadImageFromFile'},\n",
       "  {'type': 'MultiScaleFlipAug',\n",
       "   'img_scale': (416, 416),\n",
       "   'flip': False,\n",
       "   'transforms': [{'type': 'Resize', 'keep_ratio': True},\n",
       "    {'type': 'RandomFlip'},\n",
       "    {'type': 'Pad',\n",
       "     'pad_to_square': True,\n",
       "     'pad_val': {'img': (114.0, 114.0, 114.0)}},\n",
       "    {'type': 'DefaultFormatBundle'},\n",
       "    {'type': 'Collect', 'keys': ['img']}]}],\n",
       " 'data': {'samples_per_gpu': 8,\n",
       "  'workers_per_gpu': 4,\n",
       "  'persistent_workers': True,\n",
       "  'train': {'type': 'MultiImageMixDataset',\n",
       "   'dataset': {'type': 'CocoDataset',\n",
       "    'ann_file': '../mmdetection/data/coco/annotations/instances_train2017.json',\n",
       "    'img_prefix': '../mmdetection/data/coco/train2017',\n",
       "    'pipeline': [{'type': 'LoadImageFromFile'},\n",
       "     {'type': 'LoadAnnotations', 'with_bbox': True}],\n",
       "    'filter_empty_gt': False},\n",
       "   'pipeline': [{'type': 'Mosaic', 'img_scale': (640, 640), 'pad_val': 114.0},\n",
       "    {'type': 'RandomAffine',\n",
       "     'scaling_ratio_range': (0.5, 1.5),\n",
       "     'border': (-320, -320)},\n",
       "    {'type': 'YOLOXHSVRandomAug'},\n",
       "    {'type': 'RandomFlip', 'flip_ratio': 0.5},\n",
       "    {'type': 'Resize', 'img_scale': (640, 640), 'keep_ratio': True},\n",
       "    {'type': 'Pad',\n",
       "     'pad_to_square': True,\n",
       "     'pad_val': {'img': (114.0, 114.0, 114.0)}},\n",
       "    {'type': 'FilterAnnotations',\n",
       "     'min_gt_bbox_wh': (1, 1),\n",
       "     'keep_empty': False},\n",
       "    {'type': 'DefaultFormatBundle'},\n",
       "    {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}]},\n",
       "  'val': {'type': 'CocoDataset',\n",
       "   'ann_file': 'data/coco/annotations/instances_val2017.json',\n",
       "   'img_prefix': 'data/coco/val2017/',\n",
       "   'pipeline': [{'type': 'LoadImageFromFile'},\n",
       "    {'type': 'MultiScaleFlipAug',\n",
       "     'img_scale': (416, 416),\n",
       "     'flip': False,\n",
       "     'transforms': [{'type': 'Resize', 'keep_ratio': True},\n",
       "      {'type': 'RandomFlip'},\n",
       "      {'type': 'Pad',\n",
       "       'pad_to_square': True,\n",
       "       'pad_val': {'img': (114.0, 114.0, 114.0)}},\n",
       "      {'type': 'DefaultFormatBundle'},\n",
       "      {'type': 'Collect', 'keys': ['img']}]}]},\n",
       "  'test': {'type': 'CocoDataset',\n",
       "   'ann_file': 'data/coco/annotations/instances_val2017.json',\n",
       "   'img_prefix': 'data/coco/val2017/',\n",
       "   'pipeline': [{'type': 'LoadImageFromFile'},\n",
       "    {'type': 'MultiScaleFlipAug',\n",
       "     'img_scale': (416, 416),\n",
       "     'flip': False,\n",
       "     'transforms': [{'type': 'Resize', 'keep_ratio': True},\n",
       "      {'type': 'RandomFlip'},\n",
       "      {'type': 'Pad',\n",
       "       'pad_to_square': True,\n",
       "       'pad_val': {'img': (114.0, 114.0, 114.0)}},\n",
       "      {'type': 'DefaultFormatBundle'},\n",
       "      {'type': 'Collect', 'keys': ['img']}]}]}},\n",
       " 'max_epochs': 300,\n",
       " 'num_last_epochs': 15,\n",
       " 'interval': 10,\n",
       " 'evaluation': {'save_best': 'auto',\n",
       "  'interval': 10,\n",
       "  'dynamic_intervals': [(285, 1)],\n",
       "  'metric': 'bbox'}}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "73be65a2-9872-46cb-b547-9e5e816801a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f54b238a-4014-424c-b061-d46b9a258fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_metas': DataContainer([[{'filename': '../mmdetection/data/coco/train2017/000000391895.jpg', 'ori_filename': '000000391895.jpg', 'ori_shape': (360, 640, 3), 'img_shape': (640, 640, 3), 'pad_shape': (640, 640, 3), 'scale_factor': array([1., 1., 1., 1.], dtype=float32), 'flip': True, 'flip_direction': 'horizontal', 'img_norm_cfg': {'mean': array([0., 0., 0.], dtype=float32), 'std': array([1., 1., 1.], dtype=float32), 'to_rgb': False}}], [{'filename': '../mmdetection/data/coco/train2017/000000522418.jpg', 'ori_filename': '000000522418.jpg', 'ori_shape': (480, 640, 3), 'img_shape': (640, 640, 3), 'pad_shape': (640, 640, 3), 'scale_factor': array([1., 1., 1., 1.], dtype=float32), 'flip': True, 'flip_direction': 'horizontal', 'img_norm_cfg': {'mean': array([0., 0., 0.], dtype=float32), 'std': array([1., 1., 1.], dtype=float32), 'to_rgb': False}}], [{'filename': '../mmdetection/data/coco/train2017/000000184613.jpg', 'ori_filename': '000000184613.jpg', 'ori_shape': (336, 500, 3), 'img_shape': (640, 640, 3), 'pad_shape': (640, 640, 3), 'scale_factor': array([1., 1., 1., 1.], dtype=float32), 'flip': True, 'flip_direction': 'horizontal', 'img_norm_cfg': {'mean': array([0., 0., 0.], dtype=float32), 'std': array([1., 1., 1.], dtype=float32), 'to_rgb': False}}], [{'filename': '../mmdetection/data/coco/train2017/000000318219.jpg', 'ori_filename': '000000318219.jpg', 'ori_shape': (640, 556, 3), 'img_shape': (640, 640, 3), 'pad_shape': (640, 640, 3), 'scale_factor': array([1., 1., 1., 1.], dtype=float32), 'flip': False, 'flip_direction': None, 'img_norm_cfg': {'mean': array([0., 0., 0.], dtype=float32), 'std': array([1., 1., 1.], dtype=float32), 'to_rgb': False}}]]),\n",
       " 'img': DataContainer([tensor([[[[101., 101., 101.,  ..., 101., 101., 101.],\n",
       "           [101., 101., 101.,  ..., 101., 101., 101.],\n",
       "           [101., 101., 101.,  ..., 101., 101., 101.],\n",
       "           ...,\n",
       "           [236., 236., 235.,  ..., 101., 101., 101.],\n",
       "           [236., 236., 235.,  ..., 101., 101., 101.],\n",
       "           [236., 236., 235.,  ..., 101., 101., 101.]],\n",
       " \n",
       "          [[101., 101., 101.,  ..., 101., 101., 101.],\n",
       "           [101., 101., 101.,  ..., 101., 101., 101.],\n",
       "           [101., 101., 101.,  ..., 101., 101., 101.],\n",
       "           ...,\n",
       "           [236., 236., 235.,  ..., 101., 101., 101.],\n",
       "           [236., 236., 235.,  ..., 101., 101., 101.],\n",
       "           [236., 236., 235.,  ..., 101., 101., 101.]],\n",
       " \n",
       "          [[107., 107., 107.,  ..., 107., 107., 107.],\n",
       "           [107., 107., 107.,  ..., 107., 107., 107.],\n",
       "           [107., 107., 107.,  ..., 107., 107., 107.],\n",
       "           ...,\n",
       "           [248., 248., 247.,  ..., 107., 107., 107.],\n",
       "           [248., 248., 247.,  ..., 107., 107., 107.],\n",
       "           [248., 248., 247.,  ..., 107., 107., 107.]]]]), tensor([[[[126., 126., 126.,  ..., 126., 126., 126.],\n",
       "           [126., 126., 126.,  ..., 126., 126., 126.],\n",
       "           [126., 126., 126.,  ..., 126., 126., 126.],\n",
       "           ...,\n",
       "           [226., 227., 226.,  ..., 126., 126., 126.],\n",
       "           [225., 224., 224.,  ..., 126., 126., 126.],\n",
       "           [227., 226., 224.,  ..., 126., 126., 126.]],\n",
       " \n",
       "          [[126., 126., 126.,  ..., 126., 126., 126.],\n",
       "           [126., 126., 126.,  ..., 126., 126., 126.],\n",
       "           [126., 126., 126.,  ..., 126., 126., 126.],\n",
       "           ...,\n",
       "           [164., 163., 162.,  ..., 126., 126., 126.],\n",
       "           [161., 163., 164.,  ..., 126., 126., 126.],\n",
       "           [166., 165., 165.,  ..., 126., 126., 126.]],\n",
       " \n",
       "          [[126., 126., 126.,  ..., 126., 126., 126.],\n",
       "           [126., 126., 126.,  ..., 126., 126., 126.],\n",
       "           [126., 126., 126.,  ..., 126., 126., 126.],\n",
       "           ...,\n",
       "           [123., 126., 125.,  ..., 126., 126., 126.],\n",
       "           [124., 122., 124.,  ..., 126., 126., 126.],\n",
       "           [125., 125., 126.,  ..., 126., 126., 126.]]]]), tensor([[[[132., 132., 132.,  ..., 132., 132., 132.],\n",
       "           [132., 132., 132.,  ..., 132., 132., 132.],\n",
       "           [132., 132., 132.,  ..., 132., 132., 132.],\n",
       "           ...,\n",
       "           [ 78.,  76.,  78.,  ..., 132., 132., 132.],\n",
       "           [132., 129., 123.,  ..., 132., 132., 132.],\n",
       "           [132., 132., 132.,  ..., 132., 132., 132.]],\n",
       " \n",
       "          [[132., 132., 132.,  ..., 132., 132., 132.],\n",
       "           [132., 132., 132.,  ..., 132., 132., 132.],\n",
       "           [132., 132., 132.,  ..., 132., 132., 132.],\n",
       "           ...,\n",
       "           [101., 108., 102.,  ..., 132., 132., 132.],\n",
       "           [132., 130., 126.,  ..., 132., 132., 132.],\n",
       "           [132., 132., 132.,  ..., 132., 132., 132.]],\n",
       " \n",
       "          [[132., 132., 132.,  ..., 132., 132., 132.],\n",
       "           [132., 132., 132.,  ..., 132., 132., 132.],\n",
       "           [132., 132., 132.,  ..., 132., 132., 132.],\n",
       "           ...,\n",
       "           [193., 196., 199.,  ..., 132., 132., 132.],\n",
       "           [132., 134., 142.,  ..., 132., 132., 132.],\n",
       "           [132., 132., 132.,  ..., 132., 132., 132.]]]]), tensor([[[[121., 121., 121.,  ..., 121., 121., 121.],\n",
       "           [121., 121., 121.,  ..., 121., 121., 121.],\n",
       "           [121., 121., 121.,  ..., 121., 121., 121.],\n",
       "           ...,\n",
       "           [121., 121., 121.,  ...,  40.,  38.,  36.],\n",
       "           [121., 121., 121.,  ...,  38.,  37.,  37.],\n",
       "           [121., 121., 121.,  ...,  35.,  35.,  37.]],\n",
       " \n",
       "          [[121., 121., 121.,  ..., 121., 121., 121.],\n",
       "           [121., 121., 121.,  ..., 121., 121., 121.],\n",
       "           [121., 121., 121.,  ..., 121., 121., 121.],\n",
       "           ...,\n",
       "           [121., 121., 121.,  ...,  40.,  37.,  35.],\n",
       "           [121., 121., 121.,  ...,  38.,  36.,  36.],\n",
       "           [121., 121., 121.,  ...,  34.,  34.,  36.]],\n",
       " \n",
       "          [[121., 121., 121.,  ..., 121., 121., 121.],\n",
       "           [121., 121., 121.,  ..., 121., 121., 121.],\n",
       "           [121., 121., 121.,  ..., 121., 121., 121.],\n",
       "           ...,\n",
       "           [121., 121., 121.,  ...,  40.,  40.,  38.],\n",
       "           [121., 121., 121.,  ...,  38.,  39.,  39.],\n",
       "           [121., 121., 121.,  ...,  36.,  37.,  39.]]]])]),\n",
       " 'gt_bboxes': DataContainer([[tensor([[  0.0000, 203.1188,  56.6638, 499.8126],\n",
       "         [  0.0000,  45.6642,  81.6479, 449.7921]])], [tensor([[185.2508, 288.1849, 370.7080, 611.8111],\n",
       "         [321.5604, 542.7419, 466.2664, 584.0738],\n",
       "         [348.8361, 469.4608, 619.4399, 596.8658],\n",
       "         [371.7524, 395.0132, 412.0636, 448.7183],\n",
       "         [ 95.3092, 440.4566, 101.2263, 444.9880],\n",
       "         [  6.1190, 431.6224,   9.4056, 437.9087],\n",
       "         [  6.8390, 446.4379,  13.4972, 464.0948],\n",
       "         [117.2410, 438.1585, 123.1171, 442.6538],\n",
       "         [107.3480, 437.7589, 112.3672, 442.7400],\n",
       "         [ 69.6292, 443.8144,  79.3959, 450.2159],\n",
       "         [131.5273, 438.0502, 139.8353, 443.8482],\n",
       "         [ 82.7133, 442.1753,  90.5270, 447.9261],\n",
       "         [101.7438, 438.9922, 106.6844, 443.8496],\n",
       "         [130.6055, 436.2349, 135.0853, 440.8484],\n",
       "         [120.6041, 438.4021, 126.4052, 443.3739]])], [tensor([[221.0398, 197.3687, 310.7679, 272.0375],\n",
       "         [161.1437, 176.1454, 279.5560, 228.2373],\n",
       "         [130.3560, 174.1503, 163.4286, 192.0293],\n",
       "         [255.7682, 169.6380, 271.4068, 185.2002],\n",
       "         [133.5517, 167.4140, 157.5279, 178.7466],\n",
       "         [297.7726, 146.6883, 405.8347, 247.0422],\n",
       "         [417.7435, 174.1823, 432.1237, 183.6089],\n",
       "         [262.9811, 168.5578, 375.8024, 346.5594],\n",
       "         [418.7011, 172.4985, 471.7039, 277.5155],\n",
       "         [413.5900, 166.0383, 446.1178, 254.9876],\n",
       "         [432.1792, 164.7331, 463.1516, 201.5416],\n",
       "         [451.2151, 187.9258, 476.8357, 262.5414],\n",
       "         [225.9981, 164.9655, 239.2965, 185.6891],\n",
       "         [214.0394, 165.9704, 226.2633, 183.8922],\n",
       "         [202.8678, 161.3061, 211.9265, 184.3995],\n",
       "         [182.1184, 160.1492, 190.5256, 179.5055],\n",
       "         [249.7484, 161.6968, 259.4064, 184.2673],\n",
       "         [270.7283, 163.0251, 277.6499, 184.0251],\n",
       "         [283.7053, 163.4829, 288.2796, 184.9095],\n",
       "         [464.8886, 169.3658, 471.3040, 177.1691],\n",
       "         [234.9385, 181.8909, 289.2246, 201.2382],\n",
       "         [277.8060, 179.4750, 298.5435, 202.0101],\n",
       "         [134.0849, 206.8046, 299.6914, 345.3023],\n",
       "         [  0.0000, 174.3064,  36.8857, 229.3882],\n",
       "         [  0.0000, 293.2499,  37.1084, 329.2355],\n",
       "         [  0.0000, 140.6848,  42.2200, 177.5526],\n",
       "         [ 74.7092, 148.9307, 107.1721, 180.0606],\n",
       "         [ 38.3801, 279.0357,  86.9075, 329.8937],\n",
       "         [  0.0000, 116.7072,   7.7764, 142.3672],\n",
       "         [367.5884, 504.6748, 376.2044, 538.2463],\n",
       "         [127.5200, 347.5330, 461.4385, 596.3526],\n",
       "         [396.7033, 485.1445, 431.0860, 597.3577],\n",
       "         [336.0836, 475.0326, 399.1041, 595.2366],\n",
       "         [349.2747, 476.2303, 474.1481, 596.9470],\n",
       "         [450.4069, 493.0468, 475.1117, 590.0609],\n",
       "         [119.4702, 373.6077, 129.0004, 383.4658],\n",
       "         [ 53.8967, 429.4513, 128.2832, 514.5311],\n",
       "         [  0.0000, 432.5749,  39.3826, 478.1292],\n",
       "         [  0.0000, 456.5138,  30.4435, 639.7343],\n",
       "         [116.7693, 447.3846, 127.7143, 508.9078],\n",
       "         [ 22.3076, 403.7230,  82.9192, 479.2288]])], [tensor([[448.3395, 295.9830, 640.0000, 640.0000],\n",
       "         [393.7565, 245.3207, 640.0000, 640.0000]])]]),\n",
       " 'gt_labels': DataContainer([[tensor([3, 0])], [tensor([ 0, 43, 55, 71,  2,  9,  0,  2,  2,  2,  2,  2,  2,  2,  2])], [tensor([19, 19, 19, 19, 19, 25, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0, 19, 19, 19, 50, 50, 51, 51, 51, 51, 27,  7,  0,  0,  0,  0, 32,\n",
       "          2,  2,  0,  0, 38])], [tensor([0, 0])]])}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "79f213b7-fed5-48f7-8a7c-eb46ef6ddf57",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataContainer' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/79/3kl5b0ss1035q1pd2bj6rsjh0000gn/T/ipykernel_54389/3486555345.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mmcv/runner/fp16_utils.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                 f'method of those classes {supported_types}')\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fp16_enabled'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_enabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mold_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# get the arg spec of the decorated method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mmdet/models/detectors/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img, img_metas, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mmdet/models/detectors/yolox.py\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, img, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_bboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_bboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         losses = super(YOLOX, self).forward_train(img, img_metas, gt_bboxes,\n\u001b[0m\u001b[1;32m     96\u001b[0m                                                   gt_labels, gt_bboxes_ignore)\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mmdet/models/detectors/single_stage.py\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, img, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mof\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSingleStageDetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         losses = self.bbox_head.forward_train(x, img_metas, gt_bboxes,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/mmdet/models/detectors/base.py\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, imgs, img_metas, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# in DETR, this is needed for the construction of masks, which is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# then used for the transformer_head.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mbatch_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimg_meta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mimg_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_input_shape'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataContainer' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "358986ae-50d2-4f74-8b18-edb257c9032f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "The iteration step during training.\n",
       "\n",
       "This method defines an iteration step during training, except for the\n",
       "back propagation and optimizer updating, which are done in an optimizer\n",
       "hook. Note that in some complicated cases or models, the whole process\n",
       "including back propagation and optimizer updating is also defined in\n",
       "this method, such as GAN.\n",
       "\n",
       "Args:\n",
       "    data (dict): The output of dataloader.\n",
       "    optimizer (:obj:`torch.optim.Optimizer` | dict): The optimizer of\n",
       "        runner is passed to ``train_step()``. This argument is unused\n",
       "        and reserved.\n",
       "\n",
       "Returns:\n",
       "    dict: It should contain at least 3 keys: ``loss``, ``log_vars``,                 ``num_samples``.\n",
       "\n",
       "        - ``loss`` is a tensor for back propagation, which can be a\n",
       "          weighted sum of multiple losses.\n",
       "        - ``log_vars`` contains all the variables to be sent to the\n",
       "          logger.\n",
       "        - ``num_samples`` indicates the batch size (when the model is\n",
       "          DDP, it means the batch size on each GPU), which is used for\n",
       "          averaging the logs.\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"The iteration step during training.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        This method defines an iteration step during training, except for the\u001b[0m\n",
       "\u001b[0;34m        back propagation and optimizer updating, which are done in an optimizer\u001b[0m\n",
       "\u001b[0;34m        hook. Note that in some complicated cases or models, the whole process\u001b[0m\n",
       "\u001b[0;34m        including back propagation and optimizer updating is also defined in\u001b[0m\n",
       "\u001b[0;34m        this method, such as GAN.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Args:\u001b[0m\n",
       "\u001b[0;34m            data (dict): The output of dataloader.\u001b[0m\n",
       "\u001b[0;34m            optimizer (:obj:`torch.optim.Optimizer` | dict): The optimizer of\u001b[0m\n",
       "\u001b[0;34m                runner is passed to ``train_step()``. This argument is unused\u001b[0m\n",
       "\u001b[0;34m                and reserved.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns:\u001b[0m\n",
       "\u001b[0;34m            dict: It should contain at least 3 keys: ``loss``, ``log_vars``, \\\u001b[0m\n",
       "\u001b[0;34m                ``num_samples``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m                - ``loss`` is a tensor for back propagation, which can be a\u001b[0m\n",
       "\u001b[0;34m                  weighted sum of multiple losses.\u001b[0m\n",
       "\u001b[0;34m                - ``log_vars`` contains all the variables to be sent to the\u001b[0m\n",
       "\u001b[0;34m                  logger.\u001b[0m\n",
       "\u001b[0;34m                - ``num_samples`` indicates the batch size (when the model is\u001b[0m\n",
       "\u001b[0;34m                  DDP, it means the batch size on each GPU), which is used for\u001b[0m\n",
       "\u001b[0;34m                  averaging the logs.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_metas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.9/site-packages/mmdet/models/detectors/base.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train_step??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1b57bdde-d5c9-410d-9fdb-9430bcb94bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b056a327-1946-4149-b903-126c7c588486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.2'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmcv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b905f237-ee02-41c3-8d2c-4cf0cddeb7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "19968a29-2afe-464f-a1dc-eeb2c59ce311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5aaa55-bb2d-429d-a56e-a663cc1ca53d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
