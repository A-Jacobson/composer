{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f864c9a2a10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import composer\n",
    "from composer.datasets import coco_mmdet\n",
    "from composer.models import composer_yolox\n",
    "from torch.utils.data import DataLoader\n",
    "from composer.datasets.coco_mmdet import mmdet_collate, mmdet_get_num_samples\n",
    "from composer.core.data_spec import DataSpec\n",
    "from composer.loggers import InMemoryLogger, LogLevel, WandBLogger\n",
    "\n",
    "\n",
    "\n",
    "import logging, sys # disable logging in notebook\n",
    "logging.disable(sys.maxsize)\n",
    "\n",
    "torch.manual_seed(42) # For replicability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=12.60s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=1.80s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = coco_mmdet(path='../../data/coco', split='train')\n",
    "val_dataset = coco_mmdet(path='../../data/coco', split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = composer_yolox(model_name='yolox-s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=mmdet_collate, shuffle=True, drop_last=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=mmdet_collate, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.persistent_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = composer.optim.DecoupledSGDW(\n",
    "    model.parameters(), # Model parameters to update\n",
    "    lr=0.01, # Peak learning rate\n",
    "    momentum=0.9,\n",
    "    weight_decay=5e-4,\n",
    "    nesterov=True # If this looks large, it's because its not scaled by the LR as in non-decoupled weight decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = composer.optim.CosineAnnealingWithWarmupScheduler(\n",
    "    t_warmup=\"30ep\", # Warm up over 30 epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maustin-j\u001b[0m (\u001b[33mmosaic-ml\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workdisk/austin/composer/examples/wandb/run-20220802_235330-63cbcm6x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mosaic-ml/yolox-test/runs/63cbcm6x\" target=\"_blank\">1659484410-uptight-mule</a></strong> to <a href=\"https://wandb.ai/mosaic-ml/yolox-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_epochs = \"300ep\" # Train for 3 epochs because we're assuming Colab environment and hardware\n",
    "\n",
    "trainer = composer.trainer.Trainer(\n",
    "    model=model,\n",
    "    train_dataloader=DataSpec(train_loader, get_num_samples_in_batch=mmdet_get_num_samples),\n",
    "    eval_dataloader=DataSpec(val_loader, get_num_samples_in_batch=mmdet_get_num_samples),\n",
    "    max_duration=train_epochs,\n",
    "    optimizers=optimizer,\n",
    "    schedulers=lr_scheduler,\n",
    "    device=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    grad_accum=1,\n",
    "    loggers=[InMemoryLogger(log_level=LogLevel.BATCH), WandBLogger(project='yolox-test')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train          Epoch   0:    0%|| 0/3696 [00:03<?, ?ba/s]         /usr/local/lib/python3.9/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "train          Epoch   0:   68%|| 2526/3696 [15:39<08:00,  2.44ba/s, loss/train=11.6581]         "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workdisk/austin/composer/examples/yolo.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://k8s-container%2Bcontext%3Dr1z2%2Bpodname%3Daustin-yolox-llqm-cbqrz%2Bnamespace%3Daustin%2Bname%3Daustin-yolox-llqm%2Bimage%3Dmosaicml%252fpytorch/workdisk/austin/composer/examples/yolo.ipynb#ch0000007vscode-remote?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit()\n",
      "File \u001b[0;32m/workdisk/austin/composer/composer/trainer/trainer.py:1344\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_dataloader, train_dataloader_label, train_subset_num_batches, compute_training_metrics, duration, reset_time, schedulers, scale_schedule_ratio, step_schedulers_every_batch, eval_dataloader, eval_subset_num_batches, eval_interval, grad_accum, precision)\u001b[0m\n\u001b[1;32m   1341\u001b[0m     _validate_precision(precision, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeepspeed_enabled)\n\u001b[1;32m   1342\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mprecision \u001b[39m=\u001b[39m precision\n\u001b[0;32m-> 1344\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_loop()\n",
      "File \u001b[0;32m/workdisk/austin/composer/composer/trainer/trainer.py:1512\u001b[0m, in \u001b[0;36mTrainer._train_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39mrun_event(Event\u001b[39m.\u001b[39mBATCH_START)\n\u001b[1;32m   1507\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdata_batch({\n\u001b[1;32m   1508\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrainer/global_step\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mtimestamp\u001b[39m.\u001b[39mbatch),\n\u001b[1;32m   1509\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrainer/batch_idx\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mtimestamp\u001b[39m.\u001b[39mbatch_in_epoch\u001b[39m.\u001b[39mvalue,\n\u001b[1;32m   1510\u001b[0m })\n\u001b[0;32m-> 1512\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_batch(use_grad_scaling)\n\u001b[1;32m   1514\u001b[0m \u001b[39mif\u001b[39;00m use_grad_scaling:\n\u001b[1;32m   1515\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mupdate()\n",
      "File \u001b[0;32m/workdisk/austin/composer/composer/trainer/trainer.py:1655\u001b[0m, in \u001b[0;36mTrainer._train_batch\u001b[0;34m(self, use_grad_scaling)\u001b[0m\n\u001b[1;32m   1652\u001b[0m             total_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mstep(\n\u001b[1;32m   1653\u001b[0m                 optimizer, closure\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_microbatches(microbatches, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[1;32m   1654\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1655\u001b[0m             total_loss \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m   1656\u001b[0m                 closure\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_microbatches(microbatches, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49mitem())\n\u001b[1;32m   1657\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1658\u001b[0m     total_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_microbatches(microbatches)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 109\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workdisk/austin/composer/composer/optim/decoupled_weight_decay.py:107\u001b[0m, in \u001b[0;36mDecoupledSGDW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m--> 107\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    109\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m    110\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/workdisk/austin/composer/composer/trainer/trainer.py:1656\u001b[0m, in \u001b[0;36mTrainer._train_batch.<locals>.<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   1652\u001b[0m             total_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mstep(\n\u001b[1;32m   1653\u001b[0m                 optimizer, closure\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_microbatches(microbatches, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[1;32m   1654\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1655\u001b[0m             total_loss \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mstep(\n\u001b[0;32m-> 1656\u001b[0m                 closure\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_microbatches(microbatches, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mitem())\n\u001b[1;32m   1657\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1658\u001b[0m     total_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_microbatches(microbatches)\n",
      "File \u001b[0;32m/workdisk/austin/composer/composer/trainer/trainer.py:1751\u001b[0m, in \u001b[0;36mTrainer._train_microbatches\u001b[0;34m(self, microbatches, ddp_sync)\u001b[0m\n\u001b[1;32m   1749\u001b[0m \u001b[39mfor\u001b[39;00m microbatch_idx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mbatch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(microbatches):\n\u001b[1;32m   1750\u001b[0m     is_final_microbatch \u001b[39m=\u001b[39m microbatch_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(microbatches)\n\u001b[0;32m-> 1751\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_microbatch(use_grad_scaling, current_batch_size, total_loss, is_final_microbatch)\n\u001b[1;32m   1753\u001b[0m \u001b[39m# Unscale gradients before `Event.AFTER_TRAIN_BATCH`\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m use_grad_scaling:\n",
      "File \u001b[0;32m/workdisk/austin/composer/composer/trainer/trainer.py:1788\u001b[0m, in \u001b[0;36mTrainer._train_microbatch\u001b[0;34m(self, use_grad_scaling, current_batch_size, total_loss, is_final_microbatch)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39mrun_event(Event\u001b[39m.\u001b[39mBEFORE_FORWARD)\n\u001b[1;32m   1787\u001b[0m \u001b[39mwith\u001b[39;00m get_precision_context(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mprecision):\n\u001b[0;32m-> 1788\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39moutputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate\u001b[39m.\u001b[39;49mmodel(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate\u001b[39m.\u001b[39;49mbatch)\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39mrun_event(Event\u001b[39m.\u001b[39mAFTER_FORWARD)\n\u001b[1;32m   1792\u001b[0m \u001b[39m# loss\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workdisk/austin/composer/composer/models/mmdetection.py:69\u001b[0m, in \u001b[0;36mMMDetModel.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m---> 69\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m     70\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbatch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmcv/runner/fp16_utils.py:116\u001b[0m, in \u001b[0;36mauto_fp16.<locals>.auto_fp16_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m@auto_fp16 can only be used to decorate the \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    114\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmethod of those classes \u001b[39m\u001b[39m{\u001b[39;00msupported_types\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mfp16_enabled\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfp16_enabled):\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m old_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[39m# get the arg spec of the decorated method\u001b[39;00m\n\u001b[1;32m    119\u001b[0m args_info \u001b[39m=\u001b[39m getfullargspec(old_func)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmdet/models/detectors/base.py:172\u001b[0m, in \u001b[0;36mBaseDetector.forward\u001b[0;34m(self, img, img_metas, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39monnx_export(img[\u001b[39m0\u001b[39m], img_metas[\u001b[39m0\u001b[39m])\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m return_loss:\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_train(img, img_metas, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_test(img, img_metas, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmdet/models/detectors/yolox.py:95\u001b[0m, in \u001b[0;36mYOLOX.forward_train\u001b[0;34m(self, img, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39m# Multi-scale training\u001b[39;00m\n\u001b[1;32m     93\u001b[0m img, gt_bboxes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocess(img, gt_bboxes)\n\u001b[0;32m---> 95\u001b[0m losses \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(YOLOX, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mforward_train(img, img_metas, gt_bboxes,\n\u001b[1;32m     96\u001b[0m                                           gt_labels, gt_bboxes_ignore)\n\u001b[1;32m     98\u001b[0m \u001b[39m# random resizing\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_progress_in_iter \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_random_size_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmdet/models/detectors/single_stage.py:83\u001b[0m, in \u001b[0;36mSingleStageDetector.forward_train\u001b[0;34m(self, img, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39msuper\u001b[39m(SingleStageDetector, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mforward_train(img, img_metas)\n\u001b[1;32m     82\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_feat(img)\n\u001b[0;32m---> 83\u001b[0m losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbbox_head\u001b[39m.\u001b[39;49mforward_train(x, img_metas, gt_bboxes,\n\u001b[1;32m     84\u001b[0m                                       gt_labels, gt_bboxes_ignore)\n\u001b[1;32m     85\u001b[0m \u001b[39mreturn\u001b[39;00m losses\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmdet/models/dense_heads/base_dense_head.py:335\u001b[0m, in \u001b[0;36mBaseDenseHead.forward_train\u001b[0;34m(self, x, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore, proposal_cfg, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     loss_inputs \u001b[39m=\u001b[39m outs \u001b[39m+\u001b[39m (gt_bboxes, gt_labels, img_metas)\n\u001b[0;32m--> 335\u001b[0m losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(\u001b[39m*\u001b[39;49mloss_inputs, gt_bboxes_ignore\u001b[39m=\u001b[39;49mgt_bboxes_ignore)\n\u001b[1;32m    336\u001b[0m \u001b[39mif\u001b[39;00m proposal_cfg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m     \u001b[39mreturn\u001b[39;00m losses\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmcv/runner/fp16_utils.py:205\u001b[0m, in \u001b[0;36mforce_fp32.<locals>.force_fp32_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m@force_fp32 can only be used to decorate the \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    203\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mmethod of nn.Module\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mfp16_enabled\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfp16_enabled):\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m old_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39m# get the arg spec of the decorated method\u001b[39;00m\n\u001b[1;32m    207\u001b[0m args_info \u001b[39m=\u001b[39m getfullargspec(old_func)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmdet/models/dense_heads/yolox_head.py:384\u001b[0m, in \u001b[0;36mYOLOXHead.loss\u001b[0;34m(self, cls_scores, bbox_preds, objectnesses, gt_bboxes, gt_labels, img_metas, gt_bboxes_ignore)\u001b[0m\n\u001b[1;32m    380\u001b[0m flatten_priors \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(mlvl_priors)\n\u001b[1;32m    381\u001b[0m flatten_bboxes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bbox_decode(flatten_priors, flatten_bbox_preds)\n\u001b[1;32m    383\u001b[0m (pos_masks, cls_targets, obj_targets, bbox_targets, l1_targets,\n\u001b[0;32m--> 384\u001b[0m  num_fg_imgs) \u001b[39m=\u001b[39m multi_apply(\n\u001b[1;32m    385\u001b[0m      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_target_single, flatten_cls_preds\u001b[39m.\u001b[39;49mdetach(),\n\u001b[1;32m    386\u001b[0m      flatten_objectness\u001b[39m.\u001b[39;49mdetach(),\n\u001b[1;32m    387\u001b[0m      flatten_priors\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mrepeat(num_imgs, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m),\n\u001b[1;32m    388\u001b[0m      flatten_bboxes\u001b[39m.\u001b[39;49mdetach(), gt_bboxes, gt_labels)\n\u001b[1;32m    390\u001b[0m \u001b[39m# The experimental results show that ‘reduce_mean’ can improve\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[39m# performance on the COCO dataset.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m num_pos \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\n\u001b[1;32m    393\u001b[0m     \u001b[39msum\u001b[39m(num_fg_imgs),\n\u001b[1;32m    394\u001b[0m     dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat,\n\u001b[1;32m    395\u001b[0m     device\u001b[39m=\u001b[39mflatten_cls_preds\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmdet/core/utils/misc.py:30\u001b[0m, in \u001b[0;36mmulti_apply\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m pfunc \u001b[39m=\u001b[39m partial(func, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mif\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m func\n\u001b[1;32m     29\u001b[0m map_results \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(pfunc, \u001b[39m*\u001b[39margs)\n\u001b[0;32m---> 30\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlist\u001b[39m, \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mmap_results)))\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmdet/models/dense_heads/yolox_head.py:464\u001b[0m, in \u001b[0;36mYOLOXHead._get_target_single\u001b[0;34m(self, cls_preds, objectness, priors, decoded_bboxes, gt_bboxes, gt_labels)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39m# YOLOX uses center priors with 0.5 offset to assign targets,\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[39m# but use center priors without offset to regress bboxes.\u001b[39;00m\n\u001b[1;32m    461\u001b[0m offset_priors \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m    462\u001b[0m     [priors[:, :\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m priors[:, \u001b[39m2\u001b[39m:] \u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m, priors[:, \u001b[39m2\u001b[39m:]], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 464\u001b[0m assign_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massigner\u001b[39m.\u001b[39;49massign(\n\u001b[1;32m    465\u001b[0m     cls_preds\u001b[39m.\u001b[39;49msigmoid() \u001b[39m*\u001b[39;49m objectness\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49msigmoid(),\n\u001b[1;32m    466\u001b[0m     offset_priors, decoded_bboxes, gt_bboxes, gt_labels)\n\u001b[1;32m    468\u001b[0m sampling_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampler\u001b[39m.\u001b[39msample(assign_result, priors, gt_bboxes)\n\u001b[1;32m    469\u001b[0m pos_inds \u001b[39m=\u001b[39m sampling_result\u001b[39m.\u001b[39mpos_inds\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmdet/core/bbox/assigners/sim_ota_assigner.py:67\u001b[0m, in \u001b[0;36mSimOTAAssigner.assign\u001b[0;34m(self, pred_scores, priors, decoded_bboxes, gt_bboxes, gt_labels, gt_bboxes_ignore, eps)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39m\"\"\"Assign gt to priors using SimOTA. It will switch to CPU mode when\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39mGPU is out of memory.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m    assign_result (obj:`AssignResult`): The assigned result.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     assign_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_assign(pred_scores, priors, decoded_bboxes,\n\u001b[1;32m     68\u001b[0m                                  gt_bboxes, gt_labels,\n\u001b[1;32m     69\u001b[0m                                  gt_bboxes_ignore, eps)\n\u001b[1;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m assign_result\n\u001b[1;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmdet/core/bbox/assigners/sim_ota_assigner.py:130\u001b[0m, in \u001b[0;36mSimOTAAssigner._assign\u001b[0;34m(self, pred_scores, priors, decoded_bboxes, gt_bboxes, gt_labels, gt_bboxes_ignore, eps)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39m# assign 0 by default\u001b[39;00m\n\u001b[1;32m    127\u001b[0m assigned_gt_inds \u001b[39m=\u001b[39m decoded_bboxes\u001b[39m.\u001b[39mnew_full((num_bboxes, ),\n\u001b[1;32m    128\u001b[0m                                            \u001b[39m0\u001b[39m,\n\u001b[1;32m    129\u001b[0m                                            dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m--> 130\u001b[0m valid_mask, is_in_boxes_and_center \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_in_gt_and_in_center_info(\n\u001b[1;32m    131\u001b[0m     priors, gt_bboxes)\n\u001b[1;32m    132\u001b[0m valid_decoded_bbox \u001b[39m=\u001b[39m decoded_bboxes[valid_mask]\n\u001b[1;32m    133\u001b[0m valid_pred_scores \u001b[39m=\u001b[39m pred_scores[valid_mask]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/mmdet/core/bbox/assigners/sim_ota_assigner.py:226\u001b[0m, in \u001b[0;36mSimOTAAssigner.get_in_gt_and_in_center_info\u001b[0;34m(self, priors, gt_bboxes)\u001b[0m\n\u001b[1;32m    222\u001b[0m is_in_gts_or_centers \u001b[39m=\u001b[39m is_in_gts_all \u001b[39m|\u001b[39m is_in_cts_all\n\u001b[1;32m    224\u001b[0m \u001b[39m# both in boxes and centers, shape: [num_fg, num_gt]\u001b[39;00m\n\u001b[1;32m    225\u001b[0m is_in_boxes_and_centers \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 226\u001b[0m     is_in_gts[is_in_gts_or_centers, :]\n\u001b[1;32m    227\u001b[0m     \u001b[39m&\u001b[39m is_in_cts[is_in_gts_or_centers, :])\n\u001b[1;32m    228\u001b[0m \u001b[39mreturn\u001b[39;00m is_in_gts_or_centers, is_in_boxes_and_centers\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state.current_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WandBLogger(project='yolox-test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "738e66666dc83b73cd364c6226f100af1e1e94f10c7cef866572a49fea76c86f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
